{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8841c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a162a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 499543 entries, 0 to 499542\n",
      "Data columns (total 21 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   ear_reservatorio_percentual        488167 non-null  float64\n",
      " 1   ear_total_mwmes                    499543 non-null  float64\n",
      " 2   val_volmax                         499543 non-null  float64\n",
      " 3   id_reservatorio                    499543 non-null  object \n",
      " 4   val_volumeutilcon                  499543 non-null  float64\n",
      " 5   ear_reservatorio_percentual_lag1   488164 non-null  float64\n",
      " 6   ear_reservatorio_percentual_lag7   488146 non-null  float64\n",
      " 7   ear_reservatorio_percentual_lag14  488125 non-null  float64\n",
      " 8   ear_reservatorio_percentual_roll7  488143 non-null  float64\n",
      " 9   ear_reservatorio_percentual_diff1  488163 non-null  float64\n",
      " 10  ear_total_mwmes_lag1               499542 non-null  float64\n",
      " 11  ear_total_mwmes_lag7               499536 non-null  float64\n",
      " 12  ear_total_mwmes_lag14              499529 non-null  float64\n",
      " 13  val_volumeutilcon_lag1             498365 non-null  float64\n",
      " 14  val_volumeutilcon_lag7             497261 non-null  float64\n",
      " 15  val_volumeutilcon_lag14            496680 non-null  float64\n",
      " 16  val_volumeutilcon_roll7            495013 non-null  float64\n",
      " 17  val_volumeutilcon_diff1            498365 non-null  float64\n",
      " 18  dia                                499543 non-null  int64  \n",
      " 19  mes                                499543 non-null  int64  \n",
      " 20  ano                                499543 non-null  int64  \n",
      "dtypes: float64(17), int64(3), object(1)\n",
      "memory usage: 80.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('', sep=';')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a87d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Definições\n",
    "target = \"val_volumeutilcon\"\n",
    "cat_col = \"id_reservatorio\"\n",
    "\n",
    "train_list, test_list = [], []\n",
    "\n",
    "# split por reservatório\n",
    "for rid, group in df.groupby(cat_col):\n",
    "    group = group.sort_values([\"ano\", \"mes\", \"dia\"])  # garante ordem temporal\n",
    "    \n",
    "    split_idx = int(len(group) * 0.7)\n",
    "    train_part = group.iloc[:split_idx].copy()\n",
    "    test_part = group.iloc[split_idx:].copy()\n",
    "    \n",
    "    # Expanding mean até t-1 no treino\n",
    "    train_part[\"id_encoded\"] = (\n",
    "        train_part[target].expanding().mean().shift(1)\n",
    "    )\n",
    "    \n",
    "    # Preenche valores NaN com média global do target no treino\n",
    "    global_mean = train_part[target].mean()\n",
    "    train_part[\"id_encoded\"].fillna(global_mean, inplace=True)\n",
    "    \n",
    "    # Para o teste, calculamos encoding usando apenas histórico do treino\n",
    "    # Concatenamos treino + teste, aplicamos expanding, mas só usamos valores válidos\n",
    "    full_series = pd.concat([train_part, test_part])\n",
    "    full_series[\"id_encoded\"] = (\n",
    "        full_series[target].expanding().mean().shift(1)\n",
    "    )\n",
    "    \n",
    "    # Só aplica para o conjunto de teste\n",
    "    test_part[\"id_encoded\"] = full_series.loc[test_part.index, \"id_encoded\"]\n",
    "    test_part[\"id_encoded\"].fillna(global_mean, inplace=True)\n",
    "\n",
    "    train_list.append(train_part)\n",
    "    test_list.append(test_part)\n",
    "\n",
    "# Junta todos os reservatórios\n",
    "train_df = pd.concat(train_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "# Define features\n",
    "features = [\n",
    "    \"id_encoded\",\n",
    "    \"val_volmax\",\n",
    "    \"ear_reservatorio_percentual_lag1\",\n",
    "    \"ear_reservatorio_percentual_lag7\",\n",
    "    \"ear_reservatorio_percentual_roll7\",\n",
    "    \"dia\",\n",
    "    \"mes\",\n",
    "    \"ano\"\n",
    "]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[[target]]\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[[target]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "X_test = X_test.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_np = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_np = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(X_train_np), torch.tensor(y_train))\n",
    "test_ds = TensorDataset(torch.tensor(X_test_np), torch.tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819bf3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "regressor = lgb.train(\n",
    "    params={\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'max_depth': 1,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8\n",
    "    },\n",
    "    train_set=lgb.Dataset(X_train, label=y_train),\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[lgb.Dataset(X_test, label=y_test)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "print(\"RMSE:\", np.sqrt(np.mean((y_test - y_pred) ** 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
